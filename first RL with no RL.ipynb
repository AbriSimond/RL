{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-06-26 15:05:39,892] Making new env: SpaceInvaders-v0\n"
     ]
    },
    {
     "ename": "DependencyNotInstalled",
     "evalue": "No module named atari_py. (HINT: you can install Atari dependencies with 'pip install gym[atari].)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDependencyNotInstalled\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-bbd3774cb329>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mGAME_TITLE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'SpaceInvaders-v0'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0matari\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGAME_TITLE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0matari\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0matari\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rgb_array'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/gym/envs/registration.pyc\u001b[0m in \u001b[0;36mmake\u001b[1;34m(self, id)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Making new env: %s'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mspec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/gym/envs/registration.pyc\u001b[0m in \u001b[0;36mmake\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Attempting to make deprecated env {}. (HINT: is there a newer registered version of this env?)'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_entry_point\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/gym/envs/registration.pyc\u001b[0m in \u001b[0;36mload\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mentry_point\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpkg_resources\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEntryPoint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'x={}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mentry_point\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pkg_resources/__init__.pyc\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, require, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2227\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrequire\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2228\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2229\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2231\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mresolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pkg_resources/__init__.pyc\u001b[0m in \u001b[0;36mresolve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2233\u001b[0m         \u001b[0mResolve\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentry\u001b[0m \u001b[0mpoint\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mits\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2234\u001b[0m         \"\"\"\n\u001b[1;32m-> 2235\u001b[1;33m         \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__import__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfromlist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'__name__'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2236\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2237\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/gym/envs/atari/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matari\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matari_env\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAtariEnv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/gym/envs/atari/atari_env.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0matari_py\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDependencyNotInstalled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}. (HINT: you can install Atari dependencies with 'pip install gym[atari].)'\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDependencyNotInstalled\u001b[0m: No module named atari_py. (HINT: you can install Atari dependencies with 'pip install gym[atari].)'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "GAME_TITLE = 'SpaceInvaders-v0'\n",
    "import gym\n",
    "atari = gym.make(GAME_TITLE)\n",
    "atari.reset()\n",
    "plt.imshow(atari.render('rgb_array'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-06-26 15:05:44,059] Making new env: FrozenLake-v0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "env = gym.make('FrozenLake-v0')\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deterministic human model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decision = {\n",
    "    0 : 'down',\n",
    "    1 : 'right',\n",
    "    2 : 'down',\n",
    "    3 : 'down', # end of first row\n",
    "    4 : 'down', \n",
    "    5 : 'down',\n",
    "    6 : 'down',\n",
    "    7 : 'down', # end of second row\n",
    "    8 : 'right',\n",
    "    9 : 'right',\n",
    "    10 : 'down',\n",
    "    11 : 'down', #end of third row\n",
    "    12 : 'right',\n",
    "    13 : 'right',\n",
    "    14 : 'right',\n",
    "    15 : 'right'\n",
    "}\n",
    "\n",
    "\n",
    "action_table = {\n",
    "    'left' : 0,\n",
    "    'down' : 1,\n",
    "    'right' : 2,\n",
    "    'up' : 3\n",
    "}\n",
    "\n",
    "def make_action(obs):\n",
    "    return action_table[decision[obs]]\n",
    "\n",
    "#SFFF\n",
    "#FHFH\n",
    "#FFFH\n",
    "#HFFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import gym\n",
    "env = gym.make('FrozenLake-v0')\n",
    "env.reset()\n",
    "\n",
    "R = []\n",
    "\n",
    "for i_episode in range(100000):\n",
    "    observation = env.reset()\n",
    "    #env.render()\n",
    "    for t in range(100):\n",
    "        #print '-------'\n",
    "        action = make_action(observation)\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        #print('observation: ' + str(observation))\n",
    "        #print 'action: ' + str(action)\n",
    "        #env.render()\n",
    "\n",
    "        if done:\n",
    "            R.append(reward)\n",
    "            break\n",
    "            \n",
    "np.mean(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple probabilistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Policy takes in a state and outputs the action probability vectors\n",
    "policy = {}\n",
    "initprob = np.array([0.25,0.25,0.25,0.25])\n",
    "for i in range(16):\n",
    "    policy[i] = initprob\n",
    "    \n",
    "def make_decision(obs, policy):\n",
    "    return np.random.choice(4, p = policy[obs] / sum(policy[obs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def epsilon_greedy_actions(best_policy, epsilon):\n",
    "    if np.random.uniform() > epsilon:\n",
    "        P = initprob\n",
    "    else:\n",
    "        P = best_policy\n",
    "        \n",
    "    return np.random.choice(4, p = P / sum(P))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-06-26 15:51:33,901] Making new env: FrozenLake-v0\n",
      "100%|██████████| 100000/100000 [00:35<00:00, 2789.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# import gym\n",
    "env = gym.make('FrozenLake-v0')\n",
    "env.reset()\n",
    "from tqdm import tqdm\n",
    "N = 100000\n",
    "global_learn_rate = 0.01\n",
    "for i_episode in tqdm(range(N)):\n",
    "    observation = env.reset()\n",
    "    #env.render()\n",
    "    \n",
    "    O = []\n",
    "    A = []\n",
    "    for t in range(100):\n",
    "        #print '-------'\n",
    "        action = epsilon_greedy_actions(policy[observation], i_episode/N) #make_decision(observation, policy)\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        O.append(observation)\n",
    "        A.append(action)\n",
    "\n",
    "        if done:\n",
    "            #print policy\n",
    "            for a,o, tt in zip(A,O,range(t)):\n",
    "                learn_rate = global_learn_rate * (0.001 + tt/t)\n",
    "                policy[o][a] = policy[o][a]*(1-learn_rate) + learn_rate*np.minimum(1,np.maximum(reward, 0))\n",
    "                policy[o] = policy[o] / sum(policy[o])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([ 0.02689874,  0.4924768 ,  0.45443487,  0.02618958]),\n",
       " 1: array([ 0.93818318,  0.02237512,  0.02041313,  0.01902858]),\n",
       " 2: array([ 0.06529779,  0.84706069,  0.04504046,  0.04260106]),\n",
       " 3: array([ 0.8212629 ,  0.01151483,  0.09070755,  0.07651471]),\n",
       " 4: array([ 0.02574937,  0.02863743,  0.03103653,  0.91457667]),\n",
       " 5: array([ 0.245025  ,  0.23774751,  0.24257475,  0.2475    ]),\n",
       " 6: array([ 0.0334975 ,  0.02543827,  0.03099968,  0.91006455]),\n",
       " 7: array([ 0.245025  ,  0.23774751,  0.24257475,  0.2475    ]),\n",
       " 8: array([ 0.06176401,  0.07252601,  0.45099501,  0.41471497]),\n",
       " 9: array([ 0.69701192,  0.09370904,  0.10477375,  0.10450528]),\n",
       " 10: array([ 0.36881336,  0.20611915,  0.17406813,  0.25099936]),\n",
       " 11: array([ 0.245025  ,  0.23774751,  0.24257475,  0.2475    ]),\n",
       " 12: array([ 0.245025  ,  0.23774751,  0.24257475,  0.2475    ]),\n",
       " 13: array([ 0.20254368,  0.20504947,  0.28216376,  0.3102431 ]),\n",
       " 14: array([ 0.20117291,  0.30670146,  0.27386038,  0.21826525]),\n",
       " 15: array([ 0.245025  ,  0.23774751,  0.24257475,  0.2475    ])}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print action_table\n",
    "print i_episode\n",
    "print observation\n",
    "#print policy\n",
    "print policy[observation] #/ sum(policy[observation])\n",
    "#SFFF\n",
    "#FHFH\n",
    "#FFFH\n",
    "#HFFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "{0: array([ 0.02618679,  0.49283589,  0.45575484,  0.02522248]), 1: array([ 0.9382047 ,  0.02223165,  0.02028379,  0.01927985]), 2: array([ 0.06151124,  0.85237005,  0.04378058,  0.04233813]), 3: array([ 0.81277021,  0.01125786,  0.09540813,  0.0805638 ]), 4: array([ 0.02595942,  0.02912823,  0.0312779 ,  0.91363446]), 5: array([ 0.245025  ,  0.23774751,  0.24257475,  0.2475    ]), 6: array([ 0.03288535,  0.0246716 ,  0.03029253,  0.91215052]), 7: array([ 0.245025  ,  0.23774751,  0.24257475,  0.2475    ]), 8: array([ 0.06169334,  0.07298332,  0.46111579,  0.40420756]), 9: array([ 0.69849421,  0.09285727,  0.10421722,  0.10443129]), 10: array([ 0.36987   ,  0.20589884,  0.17344092,  0.25079024]), 11: array([ 0.245025  ,  0.23774751,  0.24257475,  0.2475    ]), 12: array([ 0.245025  ,  0.23774751,  0.24257475,  0.2475    ]), 13: array([ 0.2020827 ,  0.2050177 ,  0.28314703,  0.30975256]), 14: array([ 0.19995115,  0.30731752,  0.27364409,  0.21908723]), 15: array([ 0.245025  ,  0.23774751,  0.24257475,  0.2475    ])}\n"
     ]
    }
   ],
   "source": [
    "print observation\n",
    "print policy[observation]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-06-26 15:52:32,726] Making new env: FrozenLake-v0\n",
      "100%|██████████| 50000/50000 [00:03<00:00, 16254.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import gym\n",
    "env = gym.make('FrozenLake-v0')\n",
    "env.reset()\n",
    "\n",
    "R = []\n",
    "\n",
    "for i_episode in tqdm(range(50000)):\n",
    "    observation = env.reset()\n",
    "    #env.render()\n",
    "    for t in range(100):\n",
    "        #print '-------'\n",
    "        action = np.argmax(policy[observation]) # np.random.choice(4, p = policy[observation] / sum(policy[observation]))#make_decision(observation, policy)\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        #print('observation: ' + str(observation))\n",
    "        #print 'action: ' + str(action)\n",
    "        #env.render()\n",
    "\n",
    "        if done:\n",
    "            R.append(reward)\n",
    "            break\n",
    "            \n",
    "np.mean(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# random walk gives 0.0138\n",
    "# 10'000 trains gives 0.0195\n",
    "# 100k trains gives 0.0129"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
