{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepro(I):\n",
    "    \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector \"\"\"\n",
    "    I = I[35:195] # crop\n",
    "    I = I[::2,::2,0] # downsample by factor of 2\n",
    "    I[I == 144] = 0 # erase background (background type 1)\n",
    "    I[I == 109] = 0 # erase background (background type 2)\n",
    "    I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n",
    "    return I.astype(np.float32)\n",
    "\n",
    "def run_episode(env,agent, n_episodes=1, ep = 0.05):\n",
    "    '''\n",
    "    A pure run_episode with an agent. Does nothing else.\n",
    "    Outputs 3 lists with one entry for every step: state, action and reward\n",
    "    '''\n",
    "    state, action, reward, value = [], [], [], []\n",
    "    episode_number = 0\n",
    "    observation = env.reset()\n",
    "    prev_x = None # used in computing the difference frame\n",
    "\n",
    "    while True:\n",
    "        # Process observation\n",
    "        cur_x = prepro(observation)\n",
    "        x = cur_x - prev_x if prev_x is not None else np.zeros(80*80)\n",
    "        x = x.reshape((1, -1))\n",
    "        prev_x = cur_x\n",
    "\n",
    "        # Execute a step:\n",
    "        v, a = agent(x,ep=ep)\n",
    "        observation, r, done, info = env.step(a)\n",
    "\n",
    "        # Store variables from run\n",
    "        state.append(x) # note that this is the state before the action was taken\n",
    "        action.append(a)\n",
    "        reward.append(r)\n",
    "        value.append(v)\n",
    "\n",
    "        if done:\n",
    "            episode_number += 1\n",
    "            observation = env.reset() # reset env\n",
    "            prev_x = None\n",
    "\n",
    "            if episode_number >= n_episodes:\n",
    "                \n",
    "                reward = np.vstack(reward)\n",
    "                action = np.vstack(action)\n",
    "                state = np.vstack(state)\n",
    "                value = np.vstack(value)\n",
    "                return state,action,reward, value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Neg:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"mul_3:0\", shape=(?,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Input, Model\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "inp = Input(shape=(80*80,))\n",
    "h = Dense(200, activation='relu')(inp)\n",
    "V = Dense(1,activation=\"tanh\", name = \"critic\")(h)\n",
    "pi = Dense(6,activation='softmax',name=\"policy-output\")(h)\n",
    "\n",
    "model = Model(inputs=inp, \n",
    "                  outputs=[V,pi])\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.losses import mean_squared_error\n",
    "\n",
    "def weighted_crossentropy(y_true,y_pred):\n",
    "    reward_true = y_true[:,0]\n",
    "    action_true = y_true[:,1:]\n",
    "    ce = K.categorical_crossentropy(y_pred, action_true)\n",
    "    wce = ce*reward_true\n",
    "    print ce\n",
    "    print wce\n",
    "    return wce\n",
    "\n",
    "model.compile(loss=[mean_squared_error, weighted_crossentropy],\n",
    "               optimizer=keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def agent(state, ep = 0.05):\n",
    "    V, aprob = model.predict(state)\n",
    "    \n",
    "    if np.random.uniform() < ep:\n",
    "        action = env.action_space.sample()\n",
    "    else:\n",
    "        action = np.argmax(aprob)\n",
    "    return V,action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-04-05 12:11:38,720] Making new env: Pong-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1: total reward: -20.000000. run mean: -20.495000. value: 0.002332. V-loss: 0.019386. pi-loss: -0.026271.\n",
      "batch 2: total reward: -20.100000. run mean: -20.491050. value: -0.074268. V-loss: 0.010134. pi-loss: -0.145981.\n",
      "batch 3: total reward: -20.200000. run mean: -20.488139. value: -0.093988. V-loss: 0.008358. pi-loss: -0.179144.\n",
      "batch 4: total reward: -20.500000. run mean: -20.488258. value: -0.129062. V-loss: 0.005192. pi-loss: -0.236542.\n",
      "batch 5: total reward: -19.900000. run mean: -20.482376. value: -0.155695. V-loss: 0.005480. pi-loss: -0.281592.\n",
      "batch 6: total reward: -19.800000. run mean: -20.475552. value: -0.182572. V-loss: 0.005054. pi-loss: -0.325699.\n",
      "batch 7: total reward: -19.700000. run mean: -20.467796. value: -0.177014. V-loss: 0.004660. pi-loss: -0.317914.\n",
      "batch 8: total reward: -20.000000. run mean: -20.463118. value: -0.207326. V-loss: 0.003414. pi-loss: -0.369155.\n",
      "batch 9: total reward: -20.300000. run mean: -20.461487. value: -0.192339. V-loss: 0.003506. pi-loss: -0.345907.\n",
      "batch 10: total reward: -19.700000. run mean: -20.453872. value: -0.214827. V-loss: 0.004006. pi-loss: -0.385090.\n",
      "batch 11: total reward: -20.000000. run mean: -20.449334. value: -0.218338. V-loss: 0.003331. pi-loss: -0.390642.\n",
      "batch 12: total reward: -19.100000. run mean: -20.435840. value: -0.249139. V-loss: 0.003620. pi-loss: -0.442072.\n",
      "batch 13: total reward: -20.200000. run mean: -20.433482. value: -0.224214. V-loss: 0.003053. pi-loss: -0.401655.\n",
      "batch 14: total reward: -19.600000. run mean: -20.425147. value: -0.233183. V-loss: 0.003436. pi-loss: -0.418716.\n",
      "batch 15: total reward: -19.900000. run mean: -20.419895. value: -0.207630. V-loss: 0.002768. pi-loss: -0.375493.\n",
      "batch 16: total reward: -19.500000. run mean: -20.410697. value: -0.255489. V-loss: 0.003138. pi-loss: -0.457769.\n",
      "batch 17: total reward: -20.600000. run mean: -20.412590. value: -0.203373. V-loss: 0.001819. pi-loss: -0.370594.\n",
      "batch 18: total reward: -20.100000. run mean: -20.409464. value: -0.260412. V-loss: 0.002609. pi-loss: -0.465798.\n",
      "batch 19: total reward: -19.800000. run mean: -20.403369. value: -0.250867. V-loss: 0.002343. pi-loss: -0.450846.\n",
      "batch 20: total reward: -18.600000. run mean: -20.385335. value: -0.256695. V-loss: 0.003136. pi-loss: -0.461779.\n",
      "batch 21: total reward: -20.300000. run mean: -20.384482. value: -0.290628. V-loss: 0.001653. pi-loss: -0.520997.\n",
      "batch 22: total reward: -19.400000. run mean: -20.374637. value: -0.290743. V-loss: 0.002478. pi-loss: -0.517795.\n",
      "batch 23: total reward: -19.900000. run mean: -20.369891. value: -0.261453. V-loss: 0.002446. pi-loss: -0.475165.\n",
      "batch 24: total reward: -20.100000. run mean: -20.367192. value: -0.284929. V-loss: 0.002451. pi-loss: -0.511660.\n",
      "batch 25: total reward: -20.000000. run mean: -20.363520. value: -0.298704. V-loss: 0.001845. pi-loss: -0.533998.\n",
      "batch 26: total reward: -20.600000. run mean: -20.365885. value: -0.257143. V-loss: 0.001533. pi-loss: -0.471989.\n",
      "batch 27: total reward: -19.400000. run mean: -20.356226. value: -0.293557. V-loss: 0.002398. pi-loss: -0.524739.\n",
      "batch 28: total reward: -20.400000. run mean: -20.356664. value: -0.281131. V-loss: 0.001476. pi-loss: -0.510930.\n",
      "batch 29: total reward: -19.100000. run mean: -20.344097. value: -0.273041. V-loss: 0.002143. pi-loss: -0.493424.\n",
      "batch 30: total reward: -20.200000. run mean: -20.342656. value: -0.313623. V-loss: 0.001775. pi-loss: -0.565617.\n",
      "batch 31: total reward: -20.100000. run mean: -20.340229. value: -0.311391. V-loss: 0.001688. pi-loss: -0.564398.\n",
      "batch 32: total reward: -20.200000. run mean: -20.338827. value: -0.328193. V-loss: 0.001223. pi-loss: -0.589291.\n",
      "batch 33: total reward: -19.900000. run mean: -20.334439. value: -0.268327. V-loss: 0.001795. pi-loss: -0.489357.\n",
      "batch 34: total reward: -19.600000. run mean: -20.327095. value: -0.290264. V-loss: 0.001480. pi-loss: -0.534874.\n",
      "batch 35: total reward: -19.800000. run mean: -20.321824. value: -0.311360. V-loss: 0.001543. pi-loss: -0.568448.\n",
      "batch 36: total reward: -20.500000. run mean: -20.323605. value: -0.299756. V-loss: 0.001080. pi-loss: -0.557435.\n",
      "batch 37: total reward: -20.300000. run mean: -20.323369. value: -0.320184. V-loss: 0.001357. pi-loss: -0.578992.\n",
      "batch 38: total reward: -20.000000. run mean: -20.320136. value: -0.290675. V-loss: 0.001719. pi-loss: -0.539664.\n",
      "batch 39: total reward: -20.000000. run mean: -20.316934. value: -0.309692. V-loss: 0.001229. pi-loss: -0.566140.\n",
      "batch 40: total reward: -20.900000. run mean: -20.322765. value: -0.292415. V-loss: 0.000535. pi-loss: -0.552752.\n",
      "batch 41: total reward: -19.400000. run mean: -20.313537. value: -0.311597. V-loss: 0.001833. pi-loss: -0.571538.\n",
      "batch 42: total reward: -20.300000. run mean: -20.313402. value: -0.322487. V-loss: 0.000885. pi-loss: -0.589170.\n",
      "batch 43: total reward: -20.000000. run mean: -20.310268. value: -0.303556. V-loss: 0.001150. pi-loss: -0.563034.\n",
      "batch 44: total reward: -20.700000. run mean: -20.314165. value: -0.316998. V-loss: 0.000684. pi-loss: -0.597749.\n",
      "batch 45: total reward: -20.200000. run mean: -20.313024. value: -0.298414. V-loss: 0.001544. pi-loss: -0.556827.\n",
      "batch 46: total reward: -19.400000. run mean: -20.303893. value: -0.342110. V-loss: 0.002290. pi-loss: -0.626552.\n",
      "batch 47: total reward: -20.300000. run mean: -20.303854. value: -0.326002. V-loss: 0.001260. pi-loss: -0.610944.\n",
      "batch 48: total reward: -19.400000. run mean: -20.294816. value: -0.333231. V-loss: 0.001518. pi-loss: -0.610169.\n",
      "batch 49: total reward: -20.000000. run mean: -20.291868. value: -0.353982. V-loss: 0.000938. pi-loss: -0.647738.\n",
      "batch 50: total reward: -20.400000. run mean: -20.292949. value: -0.307705. V-loss: 0.000682. pi-loss: -0.572691.\n",
      "batch 51: total reward: -19.800000. run mean: -20.288020. value: -0.308814. V-loss: 0.001358. pi-loss: -0.572897.\n",
      "batch 52: total reward: -20.500000. run mean: -20.290139. value: -0.282571. V-loss: 0.000725. pi-loss: -0.553305.\n",
      "batch 53: total reward: -20.400000. run mean: -20.291238. value: -0.298476. V-loss: 0.000741. pi-loss: -0.551643.\n",
      "batch 54: total reward: -19.700000. run mean: -20.285326. value: -0.307138. V-loss: 0.001421. pi-loss: -0.578209.\n",
      "batch 55: total reward: -19.300000. run mean: -20.275472. value: -0.351929. V-loss: 0.001539. pi-loss: -0.653166.\n",
      "batch 56: total reward: -20.000000. run mean: -20.272718. value: -0.285674. V-loss: 0.000865. pi-loss: -0.550908.\n",
      "batch 57: total reward: -19.700000. run mean: -20.266990. value: -0.337241. V-loss: 0.001391. pi-loss: -0.635798.\n",
      "batch 58: total reward: -19.600000. run mean: -20.260320. value: -0.329440. V-loss: 0.002091. pi-loss: -0.618453.\n",
      "batch 59: total reward: -20.500000. run mean: -20.262717. value: -0.303415. V-loss: 0.000582. pi-loss: -0.579643.\n",
      "batch 60: total reward: -19.600000. run mean: -20.256090. value: -0.331486. V-loss: 0.001274. pi-loss: -0.625035.\n",
      "batch 61: total reward: -20.300000. run mean: -20.256529. value: -0.322016. V-loss: 0.000829. pi-loss: -0.614727.\n",
      "batch 62: total reward: -20.300000. run mean: -20.256964. value: -0.335297. V-loss: 0.000682. pi-loss: -0.633569.\n",
      "batch 63: total reward: -19.900000. run mean: -20.253394. value: -0.320482. V-loss: 0.000819. pi-loss: -0.609115.\n",
      "batch 64: total reward: -20.300000. run mean: -20.253860. value: -0.369232. V-loss: 0.000867. pi-loss: -0.689588.\n",
      "batch 65: total reward: -19.200000. run mean: -20.243322. value: -0.358464. V-loss: 0.001214. pi-loss: -0.664847.\n",
      "batch 66: total reward: -20.400000. run mean: -20.244889. value: -0.322671. V-loss: 0.000731. pi-loss: -0.620617.\n",
      "batch 67: total reward: -20.100000. run mean: -20.243440. value: -0.354826. V-loss: 0.000800. pi-loss: -0.668200.\n",
      "batch 68: total reward: -20.800000. run mean: -20.249005. value: -0.312385. V-loss: 0.000311. pi-loss: -0.609119.\n",
      "batch 69: total reward: -20.500000. run mean: -20.251515. value: -0.310760. V-loss: 0.000518. pi-loss: -0.586770.\n",
      "batch 70: total reward: -21.000000. run mean: -20.259000. value: -0.287621. V-loss: 0.000251. pi-loss: -0.577666.\n",
      "batch 71: total reward: -20.400000. run mean: -20.260410. value: -0.299760. V-loss: 0.000408. pi-loss: -0.568753.\n",
      "batch 72: total reward: -20.300000. run mean: -20.260806. value: -0.372567. V-loss: 0.000699. pi-loss: -0.707212.\n",
      "batch 73: total reward: -19.800000. run mean: -20.256198. value: -0.362976. V-loss: 0.001580. pi-loss: -0.683735.\n",
      "batch 74: total reward: -19.300000. run mean: -20.246636. value: -0.372858. V-loss: 0.001349. pi-loss: -0.694454.\n",
      "batch 75: total reward: -20.300000. run mean: -20.247170. value: -0.337589. V-loss: 0.000679. pi-loss: -0.639893.\n",
      "batch 76: total reward: -19.300000. run mean: -20.237698. value: -0.363805. V-loss: 0.001329. pi-loss: -0.685422.\n",
      "batch 77: total reward: -20.000000. run mean: -20.235321. value: -0.367831. V-loss: 0.000530. pi-loss: -0.690801.\n",
      "batch 78: total reward: -20.800000. run mean: -20.240968. value: -0.310079. V-loss: 0.000404. pi-loss: -0.603596.\n",
      "batch 79: total reward: -19.400000. run mean: -20.232558. value: -0.352635. V-loss: 0.001661. pi-loss: -0.672555.\n",
      "batch 80: total reward: -20.400000. run mean: -20.234232. value: -0.364360. V-loss: 0.000674. pi-loss: -0.693359.\n",
      "batch 81: total reward: -20.500000. run mean: -20.236890. value: -0.390876. V-loss: 0.000643. pi-loss: -0.743885.\n",
      "batch 82: total reward: -19.800000. run mean: -20.232521. value: -0.375897. V-loss: 0.001439. pi-loss: -0.702427.\n",
      "batch 83: total reward: -20.600000. run mean: -20.236196. value: -0.353442. V-loss: 0.000617. pi-loss: -0.680175.\n",
      "batch 84: total reward: -19.600000. run mean: -20.229834. value: -0.391897. V-loss: 0.001065. pi-loss: -0.733105.\n",
      "batch 85: total reward: -20.000000. run mean: -20.227536. value: -0.334763. V-loss: 0.000796. pi-loss: -0.648913.\n",
      "batch 86: total reward: -20.300000. run mean: -20.228260. value: -0.373803. V-loss: 0.000571. pi-loss: -0.701870.\n",
      "batch 87: total reward: -20.600000. run mean: -20.231978. value: -0.366336. V-loss: 0.000294. pi-loss: -0.710630.\n",
      "batch 88: total reward: -20.300000. run mean: -20.232658. value: -0.351234. V-loss: 0.000485. pi-loss: -0.664096.\n",
      "batch 89: total reward: -21.000000. run mean: -20.240331. value: -0.342079. V-loss: 0.000115. pi-loss: -0.675037.\n",
      "batch 90: total reward: -19.600000. run mean: -20.233928. value: -0.368999. V-loss: 0.000916. pi-loss: -0.696085.\n",
      "batch 91: total reward: -20.800000. run mean: -20.239589. value: -0.323014. V-loss: 0.000253. pi-loss: -0.637251.\n",
      "batch 92: total reward: -19.600000. run mean: -20.233193. value: -0.380814. V-loss: 0.000845. pi-loss: -0.720800.\n",
      "batch 93: total reward: -19.800000. run mean: -20.228861. value: -0.364319. V-loss: 0.000459. pi-loss: -0.692958.\n",
      "batch 94: total reward: -19.900000. run mean: -20.225572. value: -0.394163. V-loss: 0.000456. pi-loss: -0.745200.\n",
      "batch 95: total reward: -19.200000. run mean: -20.215317. value: -0.366008. V-loss: 0.001356. pi-loss: -0.691893.\n",
      "batch 96: total reward: -20.600000. run mean: -20.219163. value: -0.343288. V-loss: 0.000468. pi-loss: -0.672247.\n",
      "batch 97: total reward: -20.300000. run mean: -20.219972. value: -0.372363. V-loss: 0.000523. pi-loss: -0.708446.\n",
      "batch 98: total reward: -19.600000. run mean: -20.213772. value: -0.376723. V-loss: 0.000985. pi-loss: -0.719178.\n",
      "batch 99: total reward: -19.900000. run mean: -20.210634. value: -0.370740. V-loss: 0.000705. pi-loss: -0.701275.\n",
      "batch 100: total reward: -21.000000. run mean: -20.218528. value: -0.327921. V-loss: 0.000097. pi-loss: -0.653672.\n",
      "batch 101: total reward: -19.100000. run mean: -20.207343. value: -0.357766. V-loss: 0.001008. pi-loss: -0.679868.\n",
      "batch 102: total reward: -20.800000. run mean: -20.213269. value: -0.393246. V-loss: 0.000568. pi-loss: -0.757275.\n",
      "batch 103: total reward: -19.300000. run mean: -20.204137. value: -0.399733. V-loss: 0.001860. pi-loss: -0.749467.\n",
      "batch 104: total reward: -18.900000. run mean: -20.191095. value: -0.387293. V-loss: 0.000926. pi-loss: -0.731348.\n",
      "batch 105: total reward: -20.200000. run mean: -20.191184. value: -0.401120. V-loss: 0.000678. pi-loss: -0.754219.\n",
      "batch 106: total reward: -21.000000. run mean: -20.199272. value: -0.343135. V-loss: 0.000314. pi-loss: -0.679827.\n",
      "batch 107: total reward: -19.500000. run mean: -20.192280. value: -0.358043. V-loss: 0.000719. pi-loss: -0.682449.\n",
      "batch 108: total reward: -19.900000. run mean: -20.189357. value: -0.380475. V-loss: 0.000734. pi-loss: -0.721536.\n",
      "batch 109: total reward: -20.700000. run mean: -20.194463. value: -0.362488. V-loss: 0.000295. pi-loss: -0.711362.\n",
      "batch 110: total reward: -19.600000. run mean: -20.188519. value: -0.336132. V-loss: 0.000478. pi-loss: -0.643372.\n",
      "batch 111: total reward: -19.000000. run mean: -20.176634. value: -0.363156. V-loss: 0.000937. pi-loss: -0.691644.\n",
      "batch 112: total reward: -19.300000. run mean: -20.167867. value: -0.363225. V-loss: 0.000895. pi-loss: -0.694836.\n",
      "batch 113: total reward: -20.300000. run mean: -20.169189. value: -0.406108. V-loss: 0.000729. pi-loss: -0.771740.\n",
      "batch 114: total reward: -20.300000. run mean: -20.170497. value: -0.386325. V-loss: 0.000361. pi-loss: -0.738052.\n",
      "batch 115: total reward: -20.400000. run mean: -20.172792. value: -0.389149. V-loss: 0.000337. pi-loss: -0.744200.\n",
      "batch 116: total reward: -20.900000. run mean: -20.180064. value: -0.357931. V-loss: 0.000155. pi-loss: -0.695504.\n",
      "batch 117: total reward: -20.700000. run mean: -20.185263. value: -0.367115. V-loss: 0.000439. pi-loss: -0.692293.\n",
      "batch 118: total reward: -20.400000. run mean: -20.187410. value: -0.359428. V-loss: 0.000532. pi-loss: -0.684273.\n",
      "batch 119: total reward: -19.800000. run mean: -20.183536. value: -0.385541. V-loss: 0.000455. pi-loss: -0.732738.\n",
      "batch 120: total reward: -19.900000. run mean: -20.180701. value: -0.383186. V-loss: 0.000671. pi-loss: -0.731226.\n",
      "batch 121: total reward: -20.100000. run mean: -20.179894. value: -0.408527. V-loss: 0.000456. pi-loss: -0.770892.\n",
      "batch 122: total reward: -19.800000. run mean: -20.176095. value: -0.382789. V-loss: 0.000855. pi-loss: -0.727606.\n",
      "batch 123: total reward: -19.900000. run mean: -20.173334. value: -0.382555. V-loss: 0.000379. pi-loss: -0.724528.\n",
      "batch 124: total reward: -21.000000. run mean: -20.181601. value: -0.329463. V-loss: 0.000082. pi-loss: -0.657220.\n",
      "batch 125: total reward: -19.600000. run mean: -20.175785. value: -0.382574. V-loss: 0.000602. pi-loss: -0.729733.\n",
      "batch 126: total reward: -19.600000. run mean: -20.170027. value: -0.402452. V-loss: 0.000529. pi-loss: -0.762994.\n",
      "batch 127: total reward: -19.800000. run mean: -20.166327. value: -0.359790. V-loss: 0.000934. pi-loss: -0.692748.\n",
      "batch 128: total reward: -20.100000. run mean: -20.165663. value: -0.412558. V-loss: 0.000640. pi-loss: -0.783871.\n",
      "batch 129: total reward: -19.900000. run mean: -20.163007. value: -0.377945. V-loss: 0.000606. pi-loss: -0.721293.\n",
      "batch 130: total reward: -19.500000. run mean: -20.156377. value: -0.364853. V-loss: 0.000586. pi-loss: -0.696498.\n",
      "batch 131: total reward: -19.400000. run mean: -20.148813. value: -0.386611. V-loss: 0.000735. pi-loss: -0.736837.\n",
      "batch 132: total reward: -21.000000. run mean: -20.157325. value: -0.321579. V-loss: 0.000055. pi-loss: -0.648614.\n",
      "batch 133: total reward: -19.600000. run mean: -20.151752. value: -0.381859. V-loss: 0.000297. pi-loss: -0.730559.\n",
      "batch 134: total reward: -20.000000. run mean: -20.150234. value: -0.380184. V-loss: 0.000564. pi-loss: -0.736862.\n",
      "batch 135: total reward: -19.100000. run mean: -20.139732. value: -0.397046. V-loss: 0.001083. pi-loss: -0.758574.\n",
      "batch 136: total reward: -20.600000. run mean: -20.144334. value: -0.375236. V-loss: 0.000221. pi-loss: -0.730630.\n",
      "batch 137: total reward: -20.300000. run mean: -20.145891. value: -0.406676. V-loss: 0.000675. pi-loss: -0.784505.\n",
      "batch 138: total reward: -20.300000. run mean: -20.147432. value: -0.359041. V-loss: 0.000180. pi-loss: -0.699511.\n",
      "batch 139: total reward: -19.000000. run mean: -20.135958. value: -0.392549. V-loss: 0.000777. pi-loss: -0.749373.\n",
      "batch 140: total reward: -20.700000. run mean: -20.141598. value: -0.341087. V-loss: 0.000058. pi-loss: -0.675365.\n",
      "batch 141: total reward: -19.800000. run mean: -20.138182. value: -0.368599. V-loss: 0.000740. pi-loss: -0.709903.\n",
      "batch 142: total reward: -19.800000. run mean: -20.134800. value: -0.353726. V-loss: 0.001380. pi-loss: -0.683469.\n",
      "batch 143: total reward: -19.400000. run mean: -20.127452. value: -0.372580. V-loss: 0.000490. pi-loss: -0.718680.\n",
      "batch 144: total reward: -19.800000. run mean: -20.124178. value: -0.377054. V-loss: 0.000368. pi-loss: -0.725118.\n",
      "batch 145: total reward: -20.800000. run mean: -20.130936. value: -0.360099. V-loss: 0.000344. pi-loss: -0.710723.\n",
      "batch 146: total reward: -20.800000. run mean: -20.137627. value: -0.386489. V-loss: 0.000455. pi-loss: -0.757577.\n",
      "batch 147: total reward: -20.300000. run mean: -20.139250. value: -0.315174. V-loss: 0.000169. pi-loss: -0.616299.\n",
      "batch 148: total reward: -20.000000. run mean: -20.137858. value: -0.352276. V-loss: 0.000633. pi-loss: -0.685352.\n",
      "batch 149: total reward: -20.600000. run mean: -20.142479. value: -0.345892. V-loss: 0.000178. pi-loss: -0.679958.\n",
      "batch 150: total reward: -20.400000. run mean: -20.145055. value: -0.395312. V-loss: 0.000519. pi-loss: -0.767675.\n",
      "batch 151: total reward: -20.300000. run mean: -20.146604. value: -0.363084. V-loss: 0.000428. pi-loss: -0.713689.\n",
      "batch 152: total reward: -19.200000. run mean: -20.137138. value: -0.351838. V-loss: 0.000980. pi-loss: -0.688084.\n",
      "batch 153: total reward: -19.700000. run mean: -20.132767. value: -0.388846. V-loss: 0.000444. pi-loss: -0.752828.\n",
      "batch 154: total reward: -20.800000. run mean: -20.139439. value: -0.333977. V-loss: 0.000055. pi-loss: -0.673643.\n",
      "batch 155: total reward: -20.700000. run mean: -20.145045. value: -0.360680. V-loss: 0.000113. pi-loss: -0.689280.\n",
      "batch 156: total reward: -20.200000. run mean: -20.145594. value: -0.348949. V-loss: 0.000484. pi-loss: -0.683087.\n",
      "batch 157: total reward: -19.300000. run mean: -20.137138. value: -0.382928. V-loss: 0.000798. pi-loss: -0.737896.\n",
      "batch 158: total reward: -19.500000. run mean: -20.130767. value: -0.376605. V-loss: 0.000727. pi-loss: -0.731677.\n",
      "batch 159: total reward: -19.400000. run mean: -20.123459. value: -0.393108. V-loss: 0.000514. pi-loss: -0.757372.\n",
      "batch 160: total reward: -20.500000. run mean: -20.127225. value: -0.381307. V-loss: 0.000084. pi-loss: -0.751438.\n",
      "batch 161: total reward: -19.600000. run mean: -20.121952. value: -0.355173. V-loss: 0.000312. pi-loss: -0.693860.\n",
      "batch 162: total reward: -19.900000. run mean: -20.119733. value: -0.385451. V-loss: 0.000709. pi-loss: -0.741300.\n",
      "batch 163: total reward: -20.100000. run mean: -20.119535. value: -0.340989. V-loss: 0.000563. pi-loss: -0.676305.\n",
      "batch 164: total reward: -20.800000. run mean: -20.126340. value: -0.321004. V-loss: 0.000048. pi-loss: -0.653239.\n",
      "batch 165: total reward: -20.300000. run mean: -20.128077. value: -0.297934. V-loss: 0.000138. pi-loss: -0.587860.\n",
      "batch 166: total reward: -20.400000. run mean: -20.130796. value: -0.336984. V-loss: 0.000407. pi-loss: -0.669655.\n",
      "batch 167: total reward: -19.900000. run mean: -20.128488. value: -0.319732. V-loss: 0.000574. pi-loss: -0.631657.\n",
      "batch 168: total reward: -19.300000. run mean: -20.120203. value: -0.368057. V-loss: 0.001265. pi-loss: -0.722869.\n",
      "batch 169: total reward: -19.800000. run mean: -20.117001. value: -0.322787. V-loss: 0.000447. pi-loss: -0.641237.\n",
      "batch 170: total reward: -19.900000. run mean: -20.114831. value: -0.389388. V-loss: 0.000797. pi-loss: -0.750557.\n",
      "batch 171: total reward: -20.500000. run mean: -20.118683. value: -0.352573. V-loss: 0.000274. pi-loss: -0.691068.\n",
      "batch 172: total reward: -20.800000. run mean: -20.125496. value: -0.320240. V-loss: 0.000387. pi-loss: -0.653907.\n",
      "batch 173: total reward: -20.200000. run mean: -20.126241. value: -0.344697. V-loss: 0.000188. pi-loss: -0.665168.\n",
      "batch 174: total reward: -19.800000. run mean: -20.122979. value: -0.357794. V-loss: 0.000494. pi-loss: -0.691478.\n",
      "batch 175: total reward: -19.500000. run mean: -20.116749. value: -0.370012. V-loss: 0.000558. pi-loss: -0.719224.\n",
      "batch 176: total reward: -20.400000. run mean: -20.119581. value: -0.326594. V-loss: 0.000279. pi-loss: -0.652618.\n",
      "batch 177: total reward: -20.200000. run mean: -20.120385. value: -0.343667. V-loss: 0.000402. pi-loss: -0.679152.\n",
      "batch 178: total reward: -20.300000. run mean: -20.122182. value: -0.330259. V-loss: 0.000176. pi-loss: -0.670754.\n",
      "batch 179: total reward: -21.000000. run mean: -20.130960. value: -0.328553. V-loss: 0.000040. pi-loss: -0.670011.\n",
      "batch 180: total reward: -20.100000. run mean: -20.130650. value: -0.360733. V-loss: 0.000212. pi-loss: -0.702951.\n",
      "batch 181: total reward: -20.500000. run mean: -20.134344. value: -0.323694. V-loss: 0.000375. pi-loss: -0.652197.\n",
      "batch 182: total reward: -20.000000. run mean: -20.133000. value: -0.371265. V-loss: 0.001166. pi-loss: -0.720834.\n",
      "batch 183: total reward: -20.500000. run mean: -20.136670. value: -0.348209. V-loss: 0.000559. pi-loss: -0.695328.\n",
      "batch 184: total reward: -19.800000. run mean: -20.133304. value: -0.338321. V-loss: 0.000746. pi-loss: -0.666851.\n",
      "batch 185: total reward: -20.400000. run mean: -20.135971. value: -0.337542. V-loss: 0.000164. pi-loss: -0.689020.\n",
      "batch 186: total reward: -20.900000. run mean: -20.143611. value: -0.342573. V-loss: 0.000080. pi-loss: -0.693684.\n",
      "batch 187: total reward: -20.300000. run mean: -20.145175. value: -0.353320. V-loss: 0.000444. pi-loss: -0.706180.\n",
      "batch 188: total reward: -20.600000. run mean: -20.149723. value: -0.316001. V-loss: 0.000241. pi-loss: -0.647386.\n",
      "batch 189: total reward: -20.600000. run mean: -20.154226. value: -0.302742. V-loss: 0.000213. pi-loss: -0.624611.\n",
      "batch 190: total reward: -20.500000. run mean: -20.157683. value: -0.289180. V-loss: 0.000067. pi-loss: -0.575845.\n",
      "batch 191: total reward: -20.200000. run mean: -20.158107. value: -0.318761. V-loss: 0.000237. pi-loss: -0.644826.\n",
      "batch 192: total reward: -19.700000. run mean: -20.153526. value: -0.332591. V-loss: 0.000260. pi-loss: -0.668702.\n",
      "batch 193: total reward: -20.800000. run mean: -20.159990. value: -0.300256. V-loss: 0.000063. pi-loss: -0.622748.\n",
      "batch 194: total reward: -19.900000. run mean: -20.157390. value: -0.312515. V-loss: 0.000645. pi-loss: -0.611371.\n",
      "batch 195: total reward: -19.300000. run mean: -20.148816. value: -0.320565. V-loss: 0.000608. pi-loss: -0.636063.\n",
      "batch 196: total reward: -19.700000. run mean: -20.144328. value: -0.317882. V-loss: 0.000660. pi-loss: -0.633514.\n",
      "batch 197: total reward: -19.700000. run mean: -20.139885. value: -0.298775. V-loss: 0.000386. pi-loss: -0.602034.\n",
      "batch 198: total reward: -19.700000. run mean: -20.135486. value: -0.341061. V-loss: 0.000542. pi-loss: -0.687008.\n",
      "batch 199: total reward: -20.900000. run mean: -20.143131. value: -0.276487. V-loss: 0.000046. pi-loss: -0.581475.\n",
      "batch 200: total reward: -19.800000. run mean: -20.139700. value: -0.338274. V-loss: 0.000526. pi-loss: -0.670203.\n",
      "batch 201: total reward: -20.000000. run mean: -20.138303. value: -0.306547. V-loss: 0.000163. pi-loss: -0.621678.\n",
      "batch 202: total reward: -19.900000. run mean: -20.135920. value: -0.333177. V-loss: 0.000272. pi-loss: -0.671244.\n",
      "batch 203: total reward: -19.900000. run mean: -20.133561. value: -0.328460. V-loss: 0.000156. pi-loss: -0.652363.\n",
      "batch 204: total reward: -20.800000. run mean: -20.140225. value: -0.290361. V-loss: 0.000102. pi-loss: -0.604754.\n",
      "batch 205: total reward: -19.600000. run mean: -20.134823. value: -0.321469. V-loss: 0.000526. pi-loss: -0.650651.\n",
      "batch 206: total reward: -19.500000. run mean: -20.128475. value: -0.316534. V-loss: 0.000639. pi-loss: -0.633263.\n",
      "batch 207: total reward: -19.900000. run mean: -20.126190. value: -0.319717. V-loss: 0.000372. pi-loss: -0.644073.\n",
      "batch 208: total reward: -20.400000. run mean: -20.128928. value: -0.344311. V-loss: 0.000448. pi-loss: -0.673020.\n",
      "batch 209: total reward: -21.000000. run mean: -20.137639. value: -0.265339. V-loss: 0.000027. pi-loss: -0.571562.\n",
      "batch 210: total reward: -19.800000. run mean: -20.134262. value: -0.321943. V-loss: 0.000268. pi-loss: -0.622633.\n",
      "batch 211: total reward: -20.200000. run mean: -20.134920. value: -0.311167. V-loss: 0.000676. pi-loss: -0.609969.\n",
      "batch 212: total reward: -19.100000. run mean: -20.124571. value: -0.296207. V-loss: 0.000701. pi-loss: -0.585307.\n",
      "batch 213: total reward: -19.400000. run mean: -20.117325. value: -0.322187. V-loss: 0.001173. pi-loss: -0.640192.\n",
      "batch 214: total reward: -19.500000. run mean: -20.111152. value: -0.335095. V-loss: 0.000358. pi-loss: -0.656516.\n",
      "batch 215: total reward: -20.400000. run mean: -20.114040. value: -0.293216. V-loss: 0.000387. pi-loss: -0.597352.\n",
      "batch 216: total reward: -19.300000. run mean: -20.105900. value: -0.295682. V-loss: 0.000422. pi-loss: -0.589975.\n",
      "batch 217: total reward: -21.000000. run mean: -20.114841. value: -0.303912. V-loss: 0.000036. pi-loss: -0.637856.\n",
      "batch 218: total reward: -19.100000. run mean: -20.104692. value: -0.315448. V-loss: 0.001034. pi-loss: -0.622106.\n",
      "batch 219: total reward: -19.700000. run mean: -20.100645. value: -0.295311. V-loss: 0.000289. pi-loss: -0.585062.\n",
      "batch 220: total reward: -20.900000. run mean: -20.108639. value: -0.286299. V-loss: 0.000119. pi-loss: -0.599629.\n",
      "batch 221: total reward: -19.800000. run mean: -20.105553. value: -0.292801. V-loss: 0.000647. pi-loss: -0.588794.\n",
      "batch 222: total reward: -19.700000. run mean: -20.101497. value: -0.285308. V-loss: 0.000519. pi-loss: -0.575878.\n",
      "batch 223: total reward: -19.400000. run mean: -20.094482. value: -0.316115. V-loss: 0.000190. pi-loss: -0.631549.\n",
      "batch 224: total reward: -20.500000. run mean: -20.098537. value: -0.299949. V-loss: 0.000222. pi-loss: -0.617859.\n",
      "batch 225: total reward: -19.100000. run mean: -20.088552. value: -0.320758. V-loss: 0.000502. pi-loss: -0.639945.\n",
      "batch 226: total reward: -20.000000. run mean: -20.087666. value: -0.280708. V-loss: 0.000362. pi-loss: -0.574938.\n",
      "batch 227: total reward: -20.800000. run mean: -20.094790. value: -0.271128. V-loss: 0.000062. pi-loss: -0.573915.\n",
      "batch 228: total reward: -20.200000. run mean: -20.095842. value: -0.261776. V-loss: 0.000506. pi-loss: -0.526428.\n",
      "batch 229: total reward: -20.600000. run mean: -20.100883. value: -0.301989. V-loss: 0.000263. pi-loss: -0.620926.\n",
      "batch 230: total reward: -20.500000. run mean: -20.104875. value: -0.243599. V-loss: 0.000564. pi-loss: -0.494117.\n",
      "batch 231: total reward: -20.000000. run mean: -20.103826. value: -0.301452. V-loss: 0.000502. pi-loss: -0.594011.\n",
      "batch 232: total reward: -20.600000. run mean: -20.108788. value: -0.277370. V-loss: 0.000159. pi-loss: -0.577356.\n",
      "batch 233: total reward: -20.300000. run mean: -20.110700. value: -0.300435. V-loss: 0.000182. pi-loss: -0.592319.\n",
      "batch 234: total reward: -19.900000. run mean: -20.108593. value: -0.273019. V-loss: 0.000372. pi-loss: -0.545693.\n",
      "batch 235: total reward: -19.900000. run mean: -20.106507. value: -0.274281. V-loss: 0.000314. pi-loss: -0.551543.\n",
      "batch 236: total reward: -20.100000. run mean: -20.106442. value: -0.317813. V-loss: 0.000407. pi-loss: -0.637889.\n",
      "batch 237: total reward: -20.000000. run mean: -20.105377. value: -0.301253. V-loss: 0.000158. pi-loss: -0.593180.\n",
      "batch 238: total reward: -20.200000. run mean: -20.106323. value: -0.298545. V-loss: 0.000307. pi-loss: -0.593291.\n",
      "batch 239: total reward: -20.800000. run mean: -20.113260. value: -0.262247. V-loss: 0.000042. pi-loss: -0.548360.\n",
      "batch 240: total reward: -20.400000. run mean: -20.116128. value: -0.254438. V-loss: 0.000180. pi-loss: -0.508047.\n",
      "batch 241: total reward: -20.200000. run mean: -20.116966. value: -0.284263. V-loss: 0.000235. pi-loss: -0.576743.\n",
      "batch 242: total reward: -20.700000. run mean: -20.122797. value: -0.269150. V-loss: 0.000152. pi-loss: -0.562024.\n",
      "batch 243: total reward: -19.300000. run mean: -20.114569. value: -0.302101. V-loss: 0.000798. pi-loss: -0.590597.\n",
      "batch 244: total reward: -19.900000. run mean: -20.112423. value: -0.283051. V-loss: 0.000277. pi-loss: -0.571979.\n",
      "batch 245: total reward: -20.100000. run mean: -20.112299. value: -0.287954. V-loss: 0.000881. pi-loss: -0.571142.\n",
      "batch 246: total reward: -20.500000. run mean: -20.116176. value: -0.267696. V-loss: 0.000360. pi-loss: -0.551089.\n",
      "batch 247: total reward: -19.700000. run mean: -20.112014. value: -0.289463. V-loss: 0.000705. pi-loss: -0.575643.\n",
      "batch 248: total reward: -20.000000. run mean: -20.110894. value: -0.291960. V-loss: 0.000453. pi-loss: -0.600317.\n",
      "batch 249: total reward: -20.900000. run mean: -20.118785. value: -0.265715. V-loss: 0.000028. pi-loss: -0.552740.\n",
      "batch 250: total reward: -19.600000. run mean: -20.113597. value: -0.285018. V-loss: 0.000610. pi-loss: -0.564062.\n",
      "batch 251: total reward: -20.600000. run mean: -20.118461. value: -0.284052. V-loss: 0.000067. pi-loss: -0.582190.\n",
      "batch 252: total reward: -20.200000. run mean: -20.119277. value: -0.280527. V-loss: 0.000491. pi-loss: -0.567179.\n",
      "batch 253: total reward: -20.200000. run mean: -20.120084. value: -0.277681. V-loss: 0.000268. pi-loss: -0.557414.\n",
      "batch 254: total reward: -20.200000. run mean: -20.120883. value: -0.263844. V-loss: 0.000084. pi-loss: -0.517870.\n",
      "batch 255: total reward: -20.900000. run mean: -20.128674. value: -0.260423. V-loss: 0.000061. pi-loss: -0.547149.\n",
      "batch 256: total reward: -20.000000. run mean: -20.127387. value: -0.281388. V-loss: 0.000327. pi-loss: -0.558799.\n",
      "batch 257: total reward: -20.200000. run mean: -20.128113. value: -0.271064. V-loss: 0.000333. pi-loss: -0.553704.\n",
      "batch 258: total reward: -19.200000. run mean: -20.118832. value: -0.266436. V-loss: 0.000368. pi-loss: -0.534202.\n",
      "batch 259: total reward: -19.700000. run mean: -20.114644. value: -0.260880. V-loss: 0.000466. pi-loss: -0.525424.\n",
      "batch 260: total reward: -20.700000. run mean: -20.120498. value: -0.243074. V-loss: 0.000271. pi-loss: -0.503068.\n",
      "batch 261: total reward: -20.300000. run mean: -20.122293. value: -0.278489. V-loss: 0.000240. pi-loss: -0.563804.\n",
      "batch 262: total reward: -20.800000. run mean: -20.129070. value: -0.250618. V-loss: 0.000077. pi-loss: -0.516988.\n",
      "batch 263: total reward: -20.300000. run mean: -20.130779. value: -0.250607. V-loss: 0.000304. pi-loss: -0.490402.\n",
      "batch 264: total reward: -20.100000. run mean: -20.130471. value: -0.261240. V-loss: 0.000289. pi-loss: -0.524411.\n",
      "batch 265: total reward: -20.900000. run mean: -20.138166. value: -0.231653. V-loss: 0.000190. pi-loss: -0.492547.\n",
      "batch 266: total reward: -20.600000. run mean: -20.142785. value: -0.268507. V-loss: 0.000259. pi-loss: -0.551570.\n",
      "batch 267: total reward: -19.400000. run mean: -20.135357. value: -0.252083. V-loss: 0.000521. pi-loss: -0.511059.\n",
      "batch 268: total reward: -20.700000. run mean: -20.141003. value: -0.261977. V-loss: 0.000166. pi-loss: -0.541725.\n",
      "batch 269: total reward: -20.300000. run mean: -20.142593. value: -0.254425. V-loss: 0.000355. pi-loss: -0.504928.\n",
      "batch 270: total reward: -20.000000. run mean: -20.141167. value: -0.236711. V-loss: 0.000205. pi-loss: -0.484142.\n",
      "batch 271: total reward: -21.000000. run mean: -20.149756. value: -0.210385. V-loss: 0.000018. pi-loss: -0.469073.\n",
      "batch 272: total reward: -20.300000. run mean: -20.151258. value: -0.207534. V-loss: 0.000135. pi-loss: -0.428791.\n",
      "batch 273: total reward: -19.300000. run mean: -20.142746. value: -0.238321. V-loss: 0.000634. pi-loss: -0.490677.\n",
      "batch 274: total reward: -19.500000. run mean: -20.136318. value: -0.238668. V-loss: 0.000844. pi-loss: -0.506019.\n",
      "batch 275: total reward: -19.400000. run mean: -20.128955. value: -0.247717. V-loss: 0.000925. pi-loss: -0.514190.\n",
      "batch 276: total reward: -20.500000. run mean: -20.132665. value: -0.228391. V-loss: 0.000197. pi-loss: -0.485238.\n",
      "batch 277: total reward: -19.700000. run mean: -20.128339. value: -0.223861. V-loss: 0.000357. pi-loss: -0.476810.\n",
      "batch 278: total reward: -19.700000. run mean: -20.124055. value: -0.244803. V-loss: 0.000394. pi-loss: -0.517844.\n",
      "batch 279: total reward: -19.800000. run mean: -20.120815. value: -0.230302. V-loss: 0.000312. pi-loss: -0.491052.\n",
      "batch 280: total reward: -20.200000. run mean: -20.121607. value: -0.213356. V-loss: 0.000204. pi-loss: -0.465482.\n",
      "batch 281: total reward: -19.900000. run mean: -20.119391. value: -0.222014. V-loss: 0.000401. pi-loss: -0.479538.\n",
      "batch 282: total reward: -20.700000. run mean: -20.125197. value: -0.202335. V-loss: 0.000229. pi-loss: -0.454966.\n",
      "batch 283: total reward: -20.100000. run mean: -20.124945. value: -0.217996. V-loss: 0.000402. pi-loss: -0.477351.\n",
      "batch 284: total reward: -20.400000. run mean: -20.127695. value: -0.217778. V-loss: 0.000102. pi-loss: -0.477980.\n",
      "batch 285: total reward: -20.300000. run mean: -20.129418. value: -0.214225. V-loss: 0.000090. pi-loss: -0.468156.\n",
      "batch 286: total reward: -19.800000. run mean: -20.126124. value: -0.204306. V-loss: 0.000462. pi-loss: -0.447951.\n",
      "batch 287: total reward: -20.500000. run mean: -20.129863. value: -0.210299. V-loss: 0.000116. pi-loss: -0.467374.\n",
      "batch 288: total reward: -19.500000. run mean: -20.123564. value: -0.215701. V-loss: 0.000314. pi-loss: -0.474543.\n",
      "batch 289: total reward: -19.900000. run mean: -20.121329. value: -0.215432. V-loss: 0.000245. pi-loss: -0.472295.\n",
      "batch 290: total reward: -19.700000. run mean: -20.117115. value: -0.215012. V-loss: 0.000315. pi-loss: -0.467374.\n",
      "batch 291: total reward: -20.400000. run mean: -20.119944. value: -0.202307. V-loss: 0.000228. pi-loss: -0.450091.\n",
      "batch 292: total reward: -20.200000. run mean: -20.120745. value: -0.218550. V-loss: 0.000789. pi-loss: -0.482616.\n",
      "batch 293: total reward: -19.800000. run mean: -20.117537. value: -0.192990. V-loss: 0.000341. pi-loss: -0.432399.\n",
      "batch 294: total reward: -21.000000. run mean: -20.126362. value: -0.184240. V-loss: 0.000019. pi-loss: -0.424881.\n",
      "batch 295: total reward: -20.300000. run mean: -20.128098. value: -0.137394. V-loss: 0.000111. pi-loss: -0.326659.\n",
      "batch 296: total reward: -20.300000. run mean: -20.129817. value: -0.182343. V-loss: 0.000173. pi-loss: -0.417864.\n",
      "batch 297: total reward: -19.800000. run mean: -20.126519. value: -0.195859. V-loss: 0.000682. pi-loss: -0.436137.\n",
      "batch 298: total reward: -20.100000. run mean: -20.126254. value: -0.178888. V-loss: 0.000312. pi-loss: -0.406001.\n",
      "batch 299: total reward: -20.000000. run mean: -20.124991. value: -0.202198. V-loss: 0.000727. pi-loss: -0.455998.\n",
      "batch 300: total reward: -20.300000. run mean: -20.126742. value: -0.185975. V-loss: 0.000168. pi-loss: -0.421060.\n",
      "batch 301: total reward: -19.100000. run mean: -20.116474. value: -0.209817. V-loss: 0.000531. pi-loss: -0.464696.\n",
      "batch 302: total reward: -20.600000. run mean: -20.121309. value: -0.182797. V-loss: 0.000148. pi-loss: -0.422370.\n",
      "batch 303: total reward: -20.300000. run mean: -20.123096. value: -0.179980. V-loss: 0.000312. pi-loss: -0.403267.\n",
      "batch 304: total reward: -20.500000. run mean: -20.126865. value: -0.183758. V-loss: 0.000495. pi-loss: -0.421684.\n",
      "batch 305: total reward: -18.900000. run mean: -20.114597. value: -0.193084. V-loss: 0.000431. pi-loss: -0.438906.\n",
      "batch 306: total reward: -20.000000. run mean: -20.113451. value: -0.167363. V-loss: 0.000129. pi-loss: -0.385875.\n",
      "batch 307: total reward: -20.800000. run mean: -20.120316. value: -0.183094. V-loss: 0.000061. pi-loss: -0.423374.\n",
      "batch 308: total reward: -20.200000. run mean: -20.121113. value: -0.175593. V-loss: 0.000257. pi-loss: -0.403092.\n",
      "batch 309: total reward: -19.500000. run mean: -20.114902. value: -0.186188. V-loss: 0.000264. pi-loss: -0.428977.\n",
      "batch 310: total reward: -19.800000. run mean: -20.111753. value: -0.177745. V-loss: 0.000265. pi-loss: -0.416543.\n",
      "batch 311: total reward: -19.900000. run mean: -20.109635. value: -0.190199. V-loss: 0.000267. pi-loss: -0.430809.\n",
      "batch 312: total reward: -19.500000. run mean: -20.103539. value: -0.174803. V-loss: 0.000539. pi-loss: -0.405504.\n",
      "batch 313: total reward: -21.000000. run mean: -20.112504. value: -0.164073. V-loss: 0.000017. pi-loss: -0.390879.\n",
      "batch 314: total reward: -20.200000. run mean: -20.113379. value: -0.154676. V-loss: 0.000236. pi-loss: -0.362557.\n",
      "batch 315: total reward: -20.400000. run mean: -20.116245. value: -0.150195. V-loss: 0.000233. pi-loss: -0.356206.\n",
      "batch 316: total reward: -19.900000. run mean: -20.114082. value: -0.177102. V-loss: 0.000503. pi-loss: -0.414767.\n",
      "batch 317: total reward: -20.100000. run mean: -20.113942. value: -0.151521. V-loss: 0.000078. pi-loss: -0.363693.\n",
      "batch 318: total reward: -20.800000. run mean: -20.120802. value: -0.172385. V-loss: 0.000072. pi-loss: -0.407431.\n",
      "batch 319: total reward: -19.800000. run mean: -20.117594. value: -0.152401. V-loss: 0.000157. pi-loss: -0.365777.\n",
      "batch 320: total reward: -19.600000. run mean: -20.112418. value: -0.180191. V-loss: 0.000465. pi-loss: -0.422510.\n",
      "batch 321: total reward: -21.000000. run mean: -20.121294. value: -0.174474. V-loss: 0.000014. pi-loss: -0.423620.\n",
      "batch 322: total reward: -20.300000. run mean: -20.123081. value: -0.171034. V-loss: 0.000086. pi-loss: -0.413471.\n",
      "batch 323: total reward: -19.800000. run mean: -20.119850. value: -0.181836. V-loss: 0.000178. pi-loss: -0.427951.\n",
      "batch 324: total reward: -20.500000. run mean: -20.123652. value: -0.174877. V-loss: 0.000312. pi-loss: -0.417423.\n",
      "batch 325: total reward: -19.900000. run mean: -20.121415. value: -0.170999. V-loss: 0.000315. pi-loss: -0.410688.\n",
      "batch 326: total reward: -19.900000. run mean: -20.119201. value: -0.163368. V-loss: 0.000358. pi-loss: -0.392186.\n",
      "batch 327: total reward: -20.900000. run mean: -20.127009. value: -0.155216. V-loss: 0.000013. pi-loss: -0.387271.\n",
      "batch 328: total reward: -19.700000. run mean: -20.122739. value: -0.165241. V-loss: 0.000319. pi-loss: -0.392043.\n",
      "batch 329: total reward: -20.800000. run mean: -20.129512. value: -0.135695. V-loss: 0.000050. pi-loss: -0.333050.\n",
      "batch 330: total reward: -21.000000. run mean: -20.138216. value: -0.141497. V-loss: 0.000013. pi-loss: -0.377129.\n",
      "batch 331: total reward: -19.900000. run mean: -20.135834. value: -0.163598. V-loss: 0.000369. pi-loss: -0.396113.\n",
      "batch 332: total reward: -20.100000. run mean: -20.135476. value: -0.170375. V-loss: 0.000223. pi-loss: -0.409460.\n",
      "batch 333: total reward: -20.100000. run mean: -20.135121. value: -0.171215. V-loss: 0.000200. pi-loss: -0.412685.\n",
      "batch 334: total reward: -19.900000. run mean: -20.132770. value: -0.167894. V-loss: 0.000226. pi-loss: -0.407329.\n",
      "batch 335: total reward: -20.300000. run mean: -20.134442. value: -0.155363. V-loss: 0.000150. pi-loss: -0.383115.\n",
      "batch 336: total reward: -20.100000. run mean: -20.134098. value: -0.158925. V-loss: 0.000311. pi-loss: -0.394234.\n",
      "batch 337: total reward: -19.900000. run mean: -20.131757. value: -0.166217. V-loss: 0.000619. pi-loss: -0.392512.\n",
      "batch 338: total reward: -20.400000. run mean: -20.134439. value: -0.153986. V-loss: 0.000209. pi-loss: -0.379889.\n",
      "batch 339: total reward: -20.000000. run mean: -20.133095. value: -0.148810. V-loss: 0.000228. pi-loss: -0.367351.\n",
      "batch 340: total reward: -20.000000. run mean: -20.131764. value: -0.156677. V-loss: 0.000442. pi-loss: -0.379086.\n",
      "batch 341: total reward: -20.300000. run mean: -20.133446. value: -0.151824. V-loss: 0.000254. pi-loss: -0.366105.\n",
      "batch 342: total reward: -19.900000. run mean: -20.131112. value: -0.161351. V-loss: 0.000179. pi-loss: -0.377399.\n",
      "batch 343: total reward: -20.700000. run mean: -20.136801. value: -0.150322. V-loss: 0.000114. pi-loss: -0.374921.\n",
      "batch 344: total reward: -19.500000. run mean: -20.130433. value: -0.150008. V-loss: 0.000285. pi-loss: -0.360807.\n",
      "batch 345: total reward: -20.500000. run mean: -20.134128. value: -0.143798. V-loss: 0.000164. pi-loss: -0.343781.\n",
      "batch 346: total reward: -21.000000. run mean: -20.142787. value: -0.144357. V-loss: 0.000015. pi-loss: -0.362726.\n",
      "batch 347: total reward: -20.900000. run mean: -20.150359. value: -0.149342. V-loss: 0.000023. pi-loss: -0.364224.\n",
      "batch 348: total reward: -18.700000. run mean: -20.135856. value: -0.153201. V-loss: 0.000169. pi-loss: -0.372691.\n",
      "batch 349: total reward: -20.200000. run mean: -20.136497. value: -0.137912. V-loss: 0.000259. pi-loss: -0.341634.\n",
      "batch 350: total reward: -19.700000. run mean: -20.132132. value: -0.148688. V-loss: 0.000069. pi-loss: -0.363176.\n",
      "batch 351: total reward: -19.200000. run mean: -20.122811. value: -0.159685. V-loss: 0.000250. pi-loss: -0.385768.\n",
      "batch 352: total reward: -20.500000. run mean: -20.126583. value: -0.152866. V-loss: 0.000366. pi-loss: -0.380328.\n",
      "batch 353: total reward: -20.400000. run mean: -20.129317. value: -0.150097. V-loss: 0.000192. pi-loss: -0.370705.\n",
      "batch 354: total reward: -20.600000. run mean: -20.134024. value: -0.159248. V-loss: 0.000108. pi-loss: -0.384968.\n",
      "batch 355: total reward: -19.900000. run mean: -20.131683. value: -0.160577. V-loss: 0.000269. pi-loss: -0.380833.\n",
      "batch 356: total reward: -20.500000. run mean: -20.135367. value: -0.159262. V-loss: 0.000158. pi-loss: -0.375560.\n",
      "batch 357: total reward: -20.500000. run mean: -20.139013. value: -0.146688. V-loss: 0.000123. pi-loss: -0.345062.\n",
      "batch 358: total reward: -21.000000. run mean: -20.147623. value: -0.152103. V-loss: 0.000010. pi-loss: -0.369268.\n",
      "batch 359: total reward: -20.800000. run mean: -20.154147. value: -0.129699. V-loss: 0.000030. pi-loss: -0.316908.\n",
      "batch 360: total reward: -19.900000. run mean: -20.151605. value: -0.155248. V-loss: 0.000192. pi-loss: -0.368585.\n",
      "batch 361: total reward: -20.400000. run mean: -20.154089. value: -0.141293. V-loss: 0.000224. pi-loss: -0.343406.\n",
      "batch 362: total reward: -20.900000. run mean: -20.161548. value: -0.151685. V-loss: 0.000013. pi-loss: -0.367483.\n",
      "batch 363: total reward: -18.800000. run mean: -20.147933. value: -0.158623. V-loss: 0.000221. pi-loss: -0.375067.\n",
      "batch 364: total reward: -20.200000. run mean: -20.148453. value: -0.162966. V-loss: 0.000264. pi-loss: -0.381960.\n",
      "batch 365: total reward: -20.400000. run mean: -20.150969. value: -0.154555. V-loss: 0.000014. pi-loss: -0.366157.\n",
      "batch 366: total reward: -19.500000. run mean: -20.144459. value: -0.162806. V-loss: 0.000130. pi-loss: -0.387554.\n",
      "batch 367: total reward: -20.100000. run mean: -20.144015. value: -0.147544. V-loss: 0.000221. pi-loss: -0.349926.\n",
      "batch 368: total reward: -20.200000. run mean: -20.144574. value: -0.162204. V-loss: 0.000255. pi-loss: -0.380234.\n",
      "batch 369: total reward: -20.400000. run mean: -20.147129. value: -0.166265. V-loss: 0.000033. pi-loss: -0.392741.\n",
      "batch 370: total reward: -20.700000. run mean: -20.152657. value: -0.160519. V-loss: 0.000080. pi-loss: -0.373674.\n",
      "batch 371: total reward: -20.900000. run mean: -20.160131. value: -0.167950. V-loss: 0.000030. pi-loss: -0.392769.\n",
      "batch 372: total reward: -19.800000. run mean: -20.156530. value: -0.166806. V-loss: 0.000329. pi-loss: -0.389779.\n",
      "batch 373: total reward: -20.200000. run mean: -20.156964. value: -0.162376. V-loss: 0.000242. pi-loss: -0.377794.\n",
      "batch 374: total reward: -20.800000. run mean: -20.163395. value: -0.161832. V-loss: 0.000011. pi-loss: -0.376617.\n",
      "batch 375: total reward: -19.700000. run mean: -20.158761. value: -0.159078. V-loss: 0.000125. pi-loss: -0.372616.\n",
      "batch 376: total reward: -20.100000. run mean: -20.158173. value: -0.140952. V-loss: 0.000043. pi-loss: -0.332821.\n",
      "batch 377: total reward: -19.400000. run mean: -20.150591. value: -0.164903. V-loss: 0.000294. pi-loss: -0.385632.\n",
      "batch 378: total reward: -20.100000. run mean: -20.150085. value: -0.149252. V-loss: 0.000278. pi-loss: -0.350564.\n",
      "batch 379: total reward: -19.500000. run mean: -20.143585. value: -0.158086. V-loss: 0.000117. pi-loss: -0.374654.\n",
      "batch 380: total reward: -21.000000. run mean: -20.152149. value: -0.151561. V-loss: 0.000009. pi-loss: -0.358639.\n",
      "batch 381: total reward: -20.300000. run mean: -20.153627. value: -0.144653. V-loss: 0.000019. pi-loss: -0.343643.\n",
      "batch 382: total reward: -19.400000. run mean: -20.146091. value: -0.159106. V-loss: 0.000140. pi-loss: -0.374173.\n",
      "batch 383: total reward: -21.000000. run mean: -20.154630. value: -0.160450. V-loss: 0.000010. pi-loss: -0.371981.\n",
      "batch 384: total reward: -20.200000. run mean: -20.155084. value: -0.139217. V-loss: 0.000029. pi-loss: -0.332772.\n",
      "batch 385: total reward: -19.000000. run mean: -20.143533. value: -0.149914. V-loss: 0.000491. pi-loss: -0.357716.\n",
      "batch 386: total reward: -20.100000. run mean: -20.143098. value: -0.149000. V-loss: 0.000191. pi-loss: -0.352143.\n",
      "batch 387: total reward: -20.200000. run mean: -20.143667. value: -0.161352. V-loss: 0.000443. pi-loss: -0.372507.\n",
      "batch 388: total reward: -20.300000. run mean: -20.145230. value: -0.169107. V-loss: 0.000207. pi-loss: -0.382222.\n",
      "batch 389: total reward: -19.500000. run mean: -20.138778. value: -0.152954. V-loss: 0.000122. pi-loss: -0.357654.\n",
      "batch 390: total reward: -21.000000. run mean: -20.147390. value: -0.156343. V-loss: 0.000018. pi-loss: -0.359899.\n",
      "batch 391: total reward: -19.600000. run mean: -20.141916. value: -0.145074. V-loss: 0.000528. pi-loss: -0.347157.\n",
      "batch 392: total reward: -20.800000. run mean: -20.148497. value: -0.161762. V-loss: 0.000012. pi-loss: -0.363722.\n",
      "batch 393: total reward: -19.800000. run mean: -20.145012. value: -0.153416. V-loss: 0.000149. pi-loss: -0.361302.\n",
      "batch 394: total reward: -20.000000. run mean: -20.143562. value: -0.140896. V-loss: 0.000128. pi-loss: -0.340361.\n",
      "batch 395: total reward: -21.000000. run mean: -20.152126. value: -0.148644. V-loss: 0.000010. pi-loss: -0.350158.\n",
      "batch 396: total reward: -20.100000. run mean: -20.151605. value: -0.137435. V-loss: 0.000436. pi-loss: -0.334349.\n",
      "batch 397: total reward: -19.800000. run mean: -20.148089. value: -0.147818. V-loss: 0.000211. pi-loss: -0.353977.\n",
      "batch 398: total reward: -20.200000. run mean: -20.148608. value: -0.155653. V-loss: 0.000156. pi-loss: -0.362987.\n",
      "batch 399: total reward: -19.300000. run mean: -20.140122. value: -0.148939. V-loss: 0.000252. pi-loss: -0.350441.\n",
      "batch 400: total reward: -20.700000. run mean: -20.145721. value: -0.154670. V-loss: 0.000015. pi-loss: -0.368487.\n",
      "batch 401: total reward: -20.800000. run mean: -20.152263. value: -0.150007. V-loss: 0.000033. pi-loss: -0.362955.\n",
      "batch 402: total reward: -19.300000. run mean: -20.143741. value: -0.157006. V-loss: 0.000214. pi-loss: -0.383751.\n",
      "batch 403: total reward: -20.700000. run mean: -20.149303. value: -0.149951. V-loss: 0.000012. pi-loss: -0.368225.\n",
      "batch 404: total reward: -21.000000. run mean: -20.157810. value: -0.145574. V-loss: 0.000035. pi-loss: -0.359553.\n",
      "batch 405: total reward: -21.000000. run mean: -20.166232. value: -0.147556. V-loss: 0.000010. pi-loss: -0.370283.\n",
      "batch 406: total reward: -20.200000. run mean: -20.166570. value: -0.145534. V-loss: 0.000115. pi-loss: -0.366996.\n",
      "batch 407: total reward: -20.800000. run mean: -20.172904. value: -0.138202. V-loss: 0.000028. pi-loss: -0.356390.\n",
      "batch 408: total reward: -20.700000. run mean: -20.178175. value: -0.138968. V-loss: 0.000044. pi-loss: -0.357875.\n",
      "batch 409: total reward: -20.200000. run mean: -20.178393. value: -0.143440. V-loss: 0.000152. pi-loss: -0.352520.\n",
      "batch 410: total reward: -19.900000. run mean: -20.175609. value: -0.143358. V-loss: 0.000098. pi-loss: -0.350198.\n",
      "batch 411: total reward: -21.000000. run mean: -20.183853. value: -0.141054. V-loss: 0.000008. pi-loss: -0.368138.\n",
      "batch 412: total reward: -20.900000. run mean: -20.191015. value: -0.130835. V-loss: 0.000009. pi-loss: -0.353213.\n",
      "batch 413: total reward: -19.700000. run mean: -20.186105. value: -0.146464. V-loss: 0.000181. pi-loss: -0.359242.\n",
      "batch 414: total reward: -20.700000. run mean: -20.191244. value: -0.138594. V-loss: 0.000010. pi-loss: -0.361704.\n",
      "batch 415: total reward: -20.000000. run mean: -20.189331. value: -0.139597. V-loss: 0.000091. pi-loss: -0.353110.\n",
      "batch 416: total reward: -20.900000. run mean: -20.196438. value: -0.137310. V-loss: 0.000010. pi-loss: -0.360601.\n",
      "batch 417: total reward: -20.100000. run mean: -20.195473. value: -0.132884. V-loss: 0.000047. pi-loss: -0.344318.\n",
      "batch 418: total reward: -20.900000. run mean: -20.202519. value: -0.137168. V-loss: 0.000009. pi-loss: -0.363477.\n",
      "batch 419: total reward: -20.100000. run mean: -20.201494. value: -0.129750. V-loss: 0.000354. pi-loss: -0.338117.\n",
      "batch 420: total reward: -20.400000. run mean: -20.203479. value: -0.132561. V-loss: 0.000139. pi-loss: -0.337246.\n",
      "batch 421: total reward: -21.000000. run mean: -20.211444. value: -0.128354. V-loss: 0.000010. pi-loss: -0.348094.\n",
      "batch 422: total reward: -19.300000. run mean: -20.202329. value: -0.141009. V-loss: 0.000265. pi-loss: -0.355142.\n",
      "batch 423: total reward: -20.400000. run mean: -20.204306. value: -0.144049. V-loss: 0.000134. pi-loss: -0.356028.\n",
      "batch 424: total reward: -20.000000. run mean: -20.202263. value: -0.138229. V-loss: 0.000294. pi-loss: -0.345508.\n",
      "batch 425: total reward: -18.600000. run mean: -20.186240. value: -0.149980. V-loss: 0.000498. pi-loss: -0.375893.\n",
      "batch 426: total reward: -20.200000. run mean: -20.186378. value: -0.141793. V-loss: 0.000369. pi-loss: -0.355129.\n",
      "batch 427: total reward: -20.900000. run mean: -20.193514. value: -0.146290. V-loss: 0.000039. pi-loss: -0.365502.\n",
      "batch 428: total reward: -20.900000. run mean: -20.200579. value: -0.141524. V-loss: 0.000014. pi-loss: -0.364650.\n",
      "batch 429: total reward: -18.500000. run mean: -20.183573. value: -0.153176. V-loss: 0.000198. pi-loss: -0.380307.\n",
      "batch 430: total reward: -20.700000. run mean: -20.188738. value: -0.138522. V-loss: 0.000019. pi-loss: -0.351977.\n",
      "batch 431: total reward: -20.200000. run mean: -20.188850. value: -0.148643. V-loss: 0.000313. pi-loss: -0.369216.\n",
      "batch 432: total reward: -20.600000. run mean: -20.192962. value: -0.142670. V-loss: 0.000011. pi-loss: -0.355892.\n",
      "batch 433: total reward: -19.700000. run mean: -20.188032. value: -0.154943. V-loss: 0.000147. pi-loss: -0.386769.\n",
      "batch 434: total reward: -20.800000. run mean: -20.194152. value: -0.144205. V-loss: 0.000059. pi-loss: -0.364276.\n",
      "batch 435: total reward: -20.200000. run mean: -20.194210. value: -0.135623. V-loss: 0.000135. pi-loss: -0.331222.\n",
      "batch 436: total reward: -21.000000. run mean: -20.202268. value: -0.125997. V-loss: 0.000009. pi-loss: -0.347614.\n",
      "batch 437: total reward: -20.600000. run mean: -20.206245. value: -0.136904. V-loss: 0.000008. pi-loss: -0.358721.\n",
      "batch 438: total reward: -20.100000. run mean: -20.205183. value: -0.146657. V-loss: 0.000065. pi-loss: -0.362487.\n",
      "batch 439: total reward: -20.100000. run mean: -20.204131. value: -0.142867. V-loss: 0.000083. pi-loss: -0.360336.\n",
      "batch 440: total reward: -20.200000. run mean: -20.204090. value: -0.136657. V-loss: 0.000395. pi-loss: -0.343563.\n",
      "batch 441: total reward: -19.800000. run mean: -20.200049. value: -0.155080. V-loss: 0.000331. pi-loss: -0.373616.\n",
      "batch 442: total reward: -20.900000. run mean: -20.207048. value: -0.141236. V-loss: 0.000021. pi-loss: -0.355849.\n",
      "batch 443: total reward: -20.400000. run mean: -20.208978. value: -0.141677. V-loss: 0.000058. pi-loss: -0.354104.\n",
      "batch 444: total reward: -21.000000. run mean: -20.216888. value: -0.152524. V-loss: 0.000009. pi-loss: -0.367779.\n",
      "batch 445: total reward: -20.500000. run mean: -20.219719. value: -0.139225. V-loss: 0.000043. pi-loss: -0.339464.\n",
      "batch 446: total reward: -20.900000. run mean: -20.226522. value: -0.148942. V-loss: 0.000010. pi-loss: -0.363653.\n",
      "batch 447: total reward: -20.300000. run mean: -20.227257. value: -0.142506. V-loss: 0.000049. pi-loss: -0.347768.\n",
      "batch 448: total reward: -20.100000. run mean: -20.225984. value: -0.156208. V-loss: 0.000050. pi-loss: -0.367172.\n",
      "batch 449: total reward: -20.600000. run mean: -20.229724. value: -0.145790. V-loss: 0.000164. pi-loss: -0.348168.\n",
      "batch 450: total reward: -19.300000. run mean: -20.220427. value: -0.157845. V-loss: 0.000170. pi-loss: -0.375694.\n",
      "batch 451: total reward: -20.100000. run mean: -20.219223. value: -0.171056. V-loss: 0.000251. pi-loss: -0.399068.\n",
      "batch 452: total reward: -21.000000. run mean: -20.227031. value: -0.160591. V-loss: 0.000009. pi-loss: -0.383622.\n",
      "batch 453: total reward: -19.900000. run mean: -20.223760. value: -0.164685. V-loss: 0.000750. pi-loss: -0.384023.\n",
      "batch 454: total reward: -20.700000. run mean: -20.228523. value: -0.166682. V-loss: 0.000256. pi-loss: -0.386424.\n",
      "batch 455: total reward: -20.200000. run mean: -20.228238. value: -0.165193. V-loss: 0.000160. pi-loss: -0.393793.\n",
      "batch 456: total reward: -20.300000. run mean: -20.228955. value: -0.166482. V-loss: 0.000025. pi-loss: -0.392929.\n",
      "batch 457: total reward: -20.800000. run mean: -20.234666. value: -0.158777. V-loss: 0.000025. pi-loss: -0.387964.\n",
      "batch 458: total reward: -19.400000. run mean: -20.226319. value: -0.171598. V-loss: 0.000144. pi-loss: -0.408226.\n",
      "batch 459: total reward: -21.000000. run mean: -20.234056. value: -0.145408. V-loss: 0.000011. pi-loss: -0.364334.\n",
      "batch 460: total reward: -20.900000. run mean: -20.240715. value: -0.151771. V-loss: 0.000011. pi-loss: -0.373178.\n",
      "batch 461: total reward: -20.800000. run mean: -20.246308. value: -0.148516. V-loss: 0.000014. pi-loss: -0.357123.\n",
      "batch 462: total reward: -19.200000. run mean: -20.235845. value: -0.160880. V-loss: 0.000114. pi-loss: -0.381414.\n",
      "batch 463: total reward: -19.100000. run mean: -20.224487. value: -0.174294. V-loss: 0.000437. pi-loss: -0.411417.\n",
      "batch 464: total reward: -20.200000. run mean: -20.224242. value: -0.159329. V-loss: 0.000244. pi-loss: -0.394743.\n",
      "batch 465: total reward: -20.700000. run mean: -20.228999. value: -0.154214. V-loss: 0.000068. pi-loss: -0.380940.\n",
      "batch 466: total reward: -19.400000. run mean: -20.220709. value: -0.163131. V-loss: 0.000617. pi-loss: -0.393181.\n",
      "batch 467: total reward: -21.000000. run mean: -20.228502. value: -0.144004. V-loss: 0.000012. pi-loss: -0.371820.\n",
      "batch 468: total reward: -19.900000. run mean: -20.225217. value: -0.152167. V-loss: 0.000455. pi-loss: -0.379221.\n",
      "batch 469: total reward: -19.800000. run mean: -20.220965. value: -0.158557. V-loss: 0.000221. pi-loss: -0.389326.\n",
      "batch 470: total reward: -19.100000. run mean: -20.209755. value: -0.153424. V-loss: 0.000261. pi-loss: -0.376893.\n",
      "batch 471: total reward: -19.100000. run mean: -20.198658. value: -0.149734. V-loss: 0.000348. pi-loss: -0.376113.\n",
      "batch 472: total reward: -21.000000. run mean: -20.206671. value: -0.134074. V-loss: 0.000010. pi-loss: -0.362132.\n",
      "batch 473: total reward: -20.400000. run mean: -20.208605. value: -0.130386. V-loss: 0.000296. pi-loss: -0.324567.\n",
      "batch 474: total reward: -20.000000. run mean: -20.206518. value: -0.143228. V-loss: 0.000023. pi-loss: -0.362077.\n",
      "batch 475: total reward: -20.600000. run mean: -20.210453. value: -0.134353. V-loss: 0.000021. pi-loss: -0.337006.\n",
      "batch 476: total reward: -19.200000. run mean: -20.200349. value: -0.145637. V-loss: 0.000114. pi-loss: -0.372276.\n",
      "batch 477: total reward: -19.800000. run mean: -20.196345. value: -0.142175. V-loss: 0.000113. pi-loss: -0.367469.\n",
      "batch 478: total reward: -20.800000. run mean: -20.202382. value: -0.137612. V-loss: 0.000343. pi-loss: -0.365681.\n",
      "batch 479: total reward: -19.400000. run mean: -20.194358. value: -0.146920. V-loss: 0.000447. pi-loss: -0.370275.\n",
      "batch 480: total reward: -19.200000. run mean: -20.184414. value: -0.149735. V-loss: 0.000804. pi-loss: -0.371908.\n",
      "batch 481: total reward: -20.200000. run mean: -20.184570. value: -0.143339. V-loss: 0.000119. pi-loss: -0.360116.\n",
      "batch 482: total reward: -19.900000. run mean: -20.181725. value: -0.143299. V-loss: 0.000203. pi-loss: -0.353947.\n",
      "batch 483: total reward: -20.800000. run mean: -20.187907. value: -0.128696. V-loss: 0.000012. pi-loss: -0.351123.\n",
      "batch 484: total reward: -19.200000. run mean: -20.178028. value: -0.153654. V-loss: 0.000216. pi-loss: -0.376393.\n",
      "batch 485: total reward: -20.200000. run mean: -20.178248. value: -0.148240. V-loss: 0.000178. pi-loss: -0.359308.\n",
      "batch 486: total reward: -20.600000. run mean: -20.182466. value: -0.138821. V-loss: 0.000040. pi-loss: -0.327104.\n",
      "batch 487: total reward: -21.000000. run mean: -20.190641. value: -0.130182. V-loss: 0.000011. pi-loss: -0.357441.\n",
      "batch 488: total reward: -20.300000. run mean: -20.191734. value: -0.138000. V-loss: 0.000170. pi-loss: -0.328494.\n",
      "batch 489: total reward: -20.100000. run mean: -20.190817. value: -0.150745. V-loss: 0.000197. pi-loss: -0.370539.\n",
      "batch 490: total reward: -20.200000. run mean: -20.190909. value: -0.150626. V-loss: 0.000192. pi-loss: -0.361102.\n",
      "batch 491: total reward: -20.400000. run mean: -20.193000. value: -0.138895. V-loss: 0.000416. pi-loss: -0.336393.\n",
      "batch 492: total reward: -19.900000. run mean: -20.190070. value: -0.143332. V-loss: 0.000333. pi-loss: -0.359577.\n",
      "batch 493: total reward: -20.700000. run mean: -20.195169. value: -0.124768. V-loss: 0.000012. pi-loss: -0.360479.\n",
      "batch 494: total reward: -20.000000. run mean: -20.193217. value: -0.127497. V-loss: 0.000023. pi-loss: -0.358212.\n",
      "batch 495: total reward: -19.500000. run mean: -20.186285. value: -0.142427. V-loss: 0.000509. pi-loss: -0.365403.\n",
      "batch 496: total reward: -19.900000. run mean: -20.183422. value: -0.131744. V-loss: 0.000021. pi-loss: -0.365496.\n",
      "batch 497: total reward: -20.300000. run mean: -20.184588. value: -0.132161. V-loss: 0.000289. pi-loss: -0.342447.\n",
      "batch 498: total reward: -20.000000. run mean: -20.182742. value: -0.124807. V-loss: 0.000132. pi-loss: -0.328836.\n",
      "batch 499: total reward: -20.900000. run mean: -20.189915. value: -0.112706. V-loss: 0.000009. pi-loss: -0.340141.\n",
      "batch 500: total reward: -20.200000. run mean: -20.190016. value: -0.119796. V-loss: 0.000114. pi-loss: -0.309934.\n",
      "batch 501: total reward: -20.500000. run mean: -20.193116. value: -0.129663. V-loss: 0.000091. pi-loss: -0.322957.\n",
      "batch 502: total reward: -21.000000. run mean: -20.201184. value: -0.112772. V-loss: 0.000009. pi-loss: -0.347261.\n",
      "batch 503: total reward: -21.000000. run mean: -20.209173. value: -0.113470. V-loss: 0.000033. pi-loss: -0.341605.\n",
      "batch 504: total reward: -20.000000. run mean: -20.207081. value: -0.134688. V-loss: 0.000140. pi-loss: -0.342537.\n",
      "batch 505: total reward: -20.400000. run mean: -20.209010. value: -0.124969. V-loss: 0.000147. pi-loss: -0.354217.\n",
      "batch 506: total reward: -20.400000. run mean: -20.210920. value: -0.125362. V-loss: 0.000028. pi-loss: -0.314902.\n",
      "batch 507: total reward: -20.900000. run mean: -20.217811. value: -0.104036. V-loss: 0.000026. pi-loss: -0.336030.\n",
      "batch 508: total reward: -19.600000. run mean: -20.211633. value: -0.132016. V-loss: 0.000351. pi-loss: -0.357900.\n",
      "batch 509: total reward: -21.000000. run mean: -20.219516. value: -0.118611. V-loss: 0.000011. pi-loss: -0.358719.\n",
      "batch 510: total reward: -19.900000. run mean: -20.216321. value: -0.137508. V-loss: 0.000135. pi-loss: -0.341227.\n",
      "batch 511: total reward: -19.700000. run mean: -20.211158. value: -0.145225. V-loss: 0.000460. pi-loss: -0.371364.\n",
      "batch 512: total reward: -19.400000. run mean: -20.203046. value: -0.144664. V-loss: 0.000126. pi-loss: -0.354347.\n",
      "batch 513: total reward: -21.000000. run mean: -20.211016. value: -0.119597. V-loss: 0.000009. pi-loss: -0.359254.\n",
      "batch 514: total reward: -20.300000. run mean: -20.211906. value: -0.124763. V-loss: 0.000019. pi-loss: -0.325885.\n",
      "batch 515: total reward: -20.400000. run mean: -20.213787. value: -0.134873. V-loss: 0.000015. pi-loss: -0.330267.\n",
      "batch 516: total reward: -21.000000. run mean: -20.221649. value: -0.115248. V-loss: 0.000010. pi-loss: -0.350815.\n",
      "batch 517: total reward: -21.000000. run mean: -20.229432. value: -0.115359. V-loss: 0.000009. pi-loss: -0.350859.\n",
      "batch 518: total reward: -20.100000. run mean: -20.228138. value: -0.133131. V-loss: 0.000051. pi-loss: -0.346655.\n",
      "batch 519: total reward: -20.500000. run mean: -20.230857. value: -0.123794. V-loss: 0.000011. pi-loss: -0.318811.\n",
      "batch 520: total reward: -21.000000. run mean: -20.238548. value: -0.112221. V-loss: 0.000009. pi-loss: -0.344846.\n",
      "batch 521: total reward: -19.100000. run mean: -20.227163. value: -0.145558. V-loss: 0.000414. pi-loss: -0.364016.\n",
      "batch 522: total reward: -21.000000. run mean: -20.234891. value: -0.121931. V-loss: 0.000009. pi-loss: -0.350753.\n",
      "batch 523: total reward: -20.300000. run mean: -20.235542. value: -0.128587. V-loss: 0.000050. pi-loss: -0.315222.\n",
      "batch 524: total reward: -20.700000. run mean: -20.240187. value: -0.120023. V-loss: 0.000011. pi-loss: -0.355180.\n",
      "batch 525: total reward: -19.900000. run mean: -20.236785. value: -0.129344. V-loss: 0.000273. pi-loss: -0.330577.\n",
      "batch 526: total reward: -20.700000. run mean: -20.241417. value: -0.125943. V-loss: 0.000048. pi-loss: -0.335824.\n",
      "batch 527: total reward: -20.900000. run mean: -20.248003. value: -0.123560. V-loss: 0.000012. pi-loss: -0.362357.\n",
      "batch 528: total reward: -20.500000. run mean: -20.250523. value: -0.125415. V-loss: 0.000023. pi-loss: -0.310183.\n",
      "batch 529: total reward: -20.500000. run mean: -20.253017. value: -0.126258. V-loss: 0.000380. pi-loss: -0.311828.\n",
      "batch 530: total reward: -20.800000. run mean: -20.258487. value: -0.113087. V-loss: 0.000016. pi-loss: -0.334772.\n",
      "batch 531: total reward: -20.800000. run mean: -20.263902. value: -0.121792. V-loss: 0.000066. pi-loss: -0.343739.\n",
      "batch 532: total reward: -20.200000. run mean: -20.263263. value: -0.128736. V-loss: 0.000036. pi-loss: -0.336398.\n",
      "batch 533: total reward: -21.000000. run mean: -20.270631. value: -0.107390. V-loss: 0.000009. pi-loss: -0.344914.\n",
      "batch 534: total reward: -20.600000. run mean: -20.273924. value: -0.126665. V-loss: 0.000054. pi-loss: -0.312143.\n",
      "batch 535: total reward: -20.400000. run mean: -20.275185. value: -0.135459. V-loss: 0.000115. pi-loss: -0.343351.\n",
      "batch 536: total reward: -20.600000. run mean: -20.278433. value: -0.129126. V-loss: 0.000015. pi-loss: -0.326139.\n",
      "batch 537: total reward: -21.000000. run mean: -20.285649. value: -0.103719. V-loss: 0.000009. pi-loss: -0.336052.\n",
      "batch 538: total reward: -20.400000. run mean: -20.286793. value: -0.126304. V-loss: 0.000026. pi-loss: -0.310651.\n",
      "batch 539: total reward: -21.000000. run mean: -20.293925. value: -0.110386. V-loss: 0.000008. pi-loss: -0.344993.\n",
      "batch 540: total reward: -20.700000. run mean: -20.297985. value: -0.127052. V-loss: 0.000108. pi-loss: -0.358655.\n",
      "batch 541: total reward: -21.000000. run mean: -20.305006. value: -0.132384. V-loss: 0.000007. pi-loss: -0.364308.\n",
      "batch 542: total reward: -20.900000. run mean: -20.310955. value: -0.125908. V-loss: 0.000010. pi-loss: -0.360234.\n",
      "batch 543: total reward: -19.700000. run mean: -20.304846. value: -0.141575. V-loss: 0.000103. pi-loss: -0.348582.\n",
      "batch 544: total reward: -20.400000. run mean: -20.305797. value: -0.137786. V-loss: 0.000199. pi-loss: -0.330991.\n",
      "batch 545: total reward: -20.400000. run mean: -20.306739. value: -0.132019. V-loss: 0.000104. pi-loss: -0.327054.\n",
      "batch 546: total reward: -21.000000. run mean: -20.313672. value: -0.121194. V-loss: 0.000008. pi-loss: -0.364921.\n",
      "batch 547: total reward: -19.400000. run mean: -20.304535. value: -0.140533. V-loss: 0.000236. pi-loss: -0.362864.\n",
      "batch 548: total reward: -19.200000. run mean: -20.293490. value: -0.159636. V-loss: 0.000103. pi-loss: -0.387932.\n",
      "batch 549: total reward: -20.200000. run mean: -20.292555. value: -0.139940. V-loss: 0.000021. pi-loss: -0.337976.\n",
      "batch 550: total reward: -21.000000. run mean: -20.299630. value: -0.122754. V-loss: 0.000007. pi-loss: -0.358810.\n",
      "batch 551: total reward: -20.500000. run mean: -20.301633. value: -0.128628. V-loss: 0.000020. pi-loss: -0.329489.\n",
      "batch 552: total reward: -20.200000. run mean: -20.300617. value: -0.147506. V-loss: 0.000019. pi-loss: -0.357871.\n",
      "batch 553: total reward: -19.800000. run mean: -20.295611. value: -0.148736. V-loss: 0.000341. pi-loss: -0.364859.\n",
      "batch 554: total reward: -21.000000. run mean: -20.302655. value: -0.116359. V-loss: 0.000008. pi-loss: -0.354249.\n",
      "batch 555: total reward: -20.100000. run mean: -20.300628. value: -0.141736. V-loss: 0.000186. pi-loss: -0.348786.\n",
      "batch 556: total reward: -20.400000. run mean: -20.301622. value: -0.139518. V-loss: 0.000040. pi-loss: -0.329833.\n",
      "batch 557: total reward: -20.600000. run mean: -20.304606. value: -0.122298. V-loss: 0.000011. pi-loss: -0.346450.\n",
      "batch 558: total reward: -20.600000. run mean: -20.307560. value: -0.126760. V-loss: 0.000123. pi-loss: -0.330432.\n",
      "batch 559: total reward: -20.700000. run mean: -20.311484. value: -0.134336. V-loss: 0.000053. pi-loss: -0.365651.\n",
      "batch 560: total reward: -20.800000. run mean: -20.316369. value: -0.124917. V-loss: 0.000013. pi-loss: -0.354847.\n",
      "batch 561: total reward: -18.700000. run mean: -20.300205. value: -0.148394. V-loss: 0.000321. pi-loss: -0.372989.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-3b18441c833b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mV_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreward\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;31m# Value is reward if done (same as reward!=0), else it is predicted value else\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mpi_true_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mV_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Format truth value to be in accordance to weighted_crossentropy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mtotloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpiloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mV_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpi_true_weights\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;31m#print totloss, vloss, piloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# Book-keeping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1618\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1620\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1621\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1622\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2071\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2072\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m-> 2073\u001b[1;33m                               feed_dict=feed_dict)\n\u001b[0m\u001b[0;32m   2074\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2075\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 767\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 965\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1015\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1016\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1020\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1022\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1023\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "env = gym.make(\"Pong-v0\")\n",
    "running_reward = -20.5\n",
    "batch = 0\n",
    "batch_ep = 10 #how many episodes to run per batch\n",
    "ep = 0.1 # probability of random action\n",
    "while True:\n",
    "    state,action,reward, value = run_episode(env, agent, n_episodes=batch_ep, ep = ep)\n",
    "\n",
    "    # Update model\n",
    "    V_true = reward + (reward==0.0)*value # Value is reward if done (same as reward!=0), else it is predicted value else\n",
    "    pi_true_weights = np.hstack([V_true, to_categorical(action)]) # Format truth value to be in accordance to weighted_crossentropy\n",
    "    totloss, vloss, piloss = model.train_on_batch(state, [V_true, pi_true_weights])\n",
    "    #print totloss, vloss, piloss\n",
    "    # Book-keeping\n",
    "    batch +=1\n",
    "    reward_sum = np.sum(reward)/batch_ep\n",
    "    running_reward = running_reward * 0.99 + reward_sum * 0.01\n",
    "    print 'batch %d: total reward: %f. run mean: %f. value: %f. V-loss: %f. pi-loss: %f.' %\\\n",
    "    (batch, reward_sum, running_reward, np.mean(value), vloss, piloss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
